# Nanopore Pipeline for Bulk Samples

# Merge your reads. Reads should not be in multi fast5 format (i.e. 4000 reads per fast5)

#Run guppy base caller
guppy_basecaller --input_path ~/ON_data --save_path ~/ON_fastq --flowcell FLO-MIN106 --kit SQK-LSK109

# Activate python3 environment for NanoFilt
python3 -m venv /home/mmiller/panama_ON/ON_fastq/fastq_combo/
source /home/mmiller/panama_ON/ON_fastq/fastq_combo/bin/activate

# Run NanoFilt to quality filter, size filter, and remove primers. NanoFilt requires a python3 environment, so . The following assumes that you have python 3 already installled
gunzip -c 1554_all.fastq.gz | NanoFilt -q 12 -l 500 --maxlength 1000 | gzip > initial_trim1554.fastq.gz
Nanoplot -t 6 --fastq initial_trim1554.fastq.gz
gunzip -c initial_trim1554.fastq.gz | NanoFilt  -l 750 --maxlength 850 | gzip > second_trim1554.fastq.gz
Nanoplot -t 6 --fastq second_trim1554.fastq.gz

# Demultiplex reads.  (Previously, we used Porechop). We now use qcat (should trim and sort):
cat fastq_pass/*.fastq | qcat -b Wiley_out --trim -k NBD104/NBD114

# There are steps missing here. For example, how do we get from gzipped fastqs to unzipped fastqs
# Need to trim off primers, this could be a usearch step.

# Use USEARCH to cluster a single barcode read. Setting a low id  is critical
# We want to test the results with ID=0.70, ID=0.80, and ID=0.90 as a minimum
# This code also creates a consensus for each cluster using a USEARCH algorithim
./usearch.xxx... -cluster_fast barcode1.fastq -id 0.80  -consout barcode1consensus.fasta -clusters barcode1/c_
# In practice, I don't like the USEARCH consensus. It doesn't deal well with ON error, so we have move away from This

# I don't like the USEARCH algorithim for building a consensus. So we re-build a consensus with minimap. This also gets rid of much of the ON error.
minimap2 -ax map-ont MK300247.fasta barcode01_cluster_2 > cluster_2.sam
